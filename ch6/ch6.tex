\chapter{Conclusion}

While noisy sequencing data can be difficult to work with, with care it \textit{is} possible to generate high-quality calls. As both sequencing technology and software tools improve, the amount of useful information that can be extracted from sequencing experiments will continue to grow, and the costs of performing those experiments will continue to shrink. This will enable the generation of an unprecedented amount of data, particularly in organisms that have been historically neglected. This necessitates the continued development of methods that function even without \textit{a priori} information.

All together, the experiments included here show that while calling variants requires effort when reference genomes and other information is not available, it is not impossible. Most methods designed to work with reference-aligned data can work fairly well if a reference from a close relative can be adapted to the data, as shown in Chapter \ref{ch:phylogenomic}. Furthermore, Chapter \ref{ch:kbbq} shows that base quality scores can be successfully calibrated without any auxiliary information. And Chapter \ref{ch:evaluating} shows that this improvement in base quality score calibration can improve variant calling sensitivity and reduce the number of false positive calls.

In these investigations, I have highlighted and developed several methods for detecting mutations in non-model organisms. While the data used here is limited to Illumina short read sequencing, the approaches described are adaptable for even the next generation of sequencing platforms. The principles discussed and their application may prove even more useful on these platforms, as their primary drawback is high error rates. Even now, computational methods are able to overcome the error rates on these platforms and make them suitable for some applications, like assembly.

Now is an incredible time to be interested in sequencing and sequencing technology. Illumina sequencing and associated methods are relatively mature, but interesting new methods and models are still expanding the limits of the technology and achieving impressive results despite its flaws. On the horizon, long read sequencing is becoming ever more affordable, accurate, and fast, promising new avenues for investigating the natural world along with new challenges. But no matter what the future holds, one thing is clear: software and statistical methods for analyzing sequencing data will continue to be necessary to get the most out of sequencing technology and transform raw data into insights.



% As the process becomes cheaper and cheaper, the pace of data generation is expected to accelerate. Scientists will need a wide-range of computational tools available to them to succeed in their investigations. Thus, it behooves those of us who write such tools to be clear about their assumptions and limitations and to make our tools simple to install and use, while making them difficult to misuse and abuse. Interoperability and common standards will also be necessary to ensure the increasing amount of data collected turns into increasing knowledge and not wasted effort.
