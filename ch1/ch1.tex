\chapter{Introduction}

%A brief introduction that introduces topics like DNA sequencing and variant calling. Also introduces the \textit{E. melliodora} dataset used in the 2nd, 3rd, and 5th chapters.

%TODO: MANY CITES ! These things are all gonna need citations.
%TODO: maybe more background info?

Next-generation sequencing is a powerful technology with numerous applications. It has enabled data collection and hypothesis testing at an unprecedented scale, with an enormous amount of sequencing data generated daily \parencite{kodama_sequence_2012}. The high-throughput nature of modern sequencing technologies makes it cheap and efficient to genotype one or more samples. Additionally, next-generation sequencing serves as the basis of a variety of methods for interrogating a wide array of molecular functions and epigenetic states including RNA-seq \parencite{nagalakshmi_transcriptional_2008}, ChIP-seq \parencite{johnson_genome-wide_2007}, DNase-seq \parencite{boyle_high-resolution_2008}, MNAse-seq \parencite{schones_dynamic_2008}, ATAC-seq \parencite{buenrostro_atac-seq_2015}, bisfulfite sequencing \parencite{frommer_genomic_1992}, and many more. As a testament to how powerful and useful the technology is for understanding the natural world, it has achieved such widespread use despite being highly error-prone \parencite{nakamura_sequence-specific_2011, meacham_identification_2011, fox_accuracy_2014}. DNA sequencing technology continues to improve; increasing read length and reduced substitution, insertion, and deletion errors are seemingly inevitable as new methods develop and the technology is refined \parencite{branton_potential_2008, eid_real-time_2009, fox_accuracy_2014}. Yet even the most sophisticated and accurate sequencing platforms will require analysis with sound statistical methods to turn raw data into interesting and useful insights about the natural world.

In this dissertation, I explore and develop methods for gaining insight from noisy next-generation sequencing data in challenging contexts. In particular, I focus on genotyping and detecting mutations in non-model organisms. While there has been an explosion in the amount of sequencing data generated since the advent of the technology, most species on the planet have still not been sequenced; even fewer have complete and accurate reference genomes \parencite{lewin_earth_2018}. Yet, funding available specifically for the generation and refinement of new reference genomes is difficult to acquire \parencite{richards_its_2015}. Model organisms are immensely useful for generating knowledge and are vital to gaining understanding of the world; however, it is clear that model organisms do not hold the answers to every interesting question. As such, it is important and necessary to develop methods for data analysis that work well even with limited \textit{a priori} knowledge.

In the second chapter, I present collaborative work on sensitively detecting somatic mutations in the non-model eucalypt, \textit{Eucalyptus melliodora}. This work was previously published in \textit{Proceedings of the Royal Society B} and documents my and my coauthors' efforts to estimate the somatic mutation rate of an individual eucalypt. As a control, I used a conventional variant calling algorithm paired with custom filters to investigate whether the physical tree structure of the organism also gives it a tree-like genetic structure, as one may predict based on how trees grow and mature. I also investigate the limits of this approach and find bounds on the estimates of several population genetic parameters we are able to estimate from the data.

The sequencing data and calls made in the second chapter are used throughout this dissertation as a basis of comparison for many of the techniques I use. The third chapter details my investigation of base quality score recalibration, a technique used to fix inaccurate quality measurements attached to sequencing data. I introduce an efficient software program \texttt{kbbq} to perform base quality score recalibration on whole genome sequencing reads without a reference genome or other \textit{a priori} knowledge and show it performs just as well as the most common method for base quality score recalibration.

Errors are common relative to mutations in sequencing data, \parencite{fox_accuracy_2014, wu_estimating_2017} and since correlated errors are by definition non-independent, such errors cannot be detected by increased sequencing depth alone \parencite{meacham_identification_2011, taub_overcoming_2010}. Correcting quality score calibration issues in sequencing reads could in principle improve the ability of a variant caller to distinguish between true variation and noise in a way that increased depth cannot. While there is some evidence that it does help increase sensitivity \parencite{ni_improvement_2016}, it is an open question whether the benefits of base quality score recalibration outweigh the time, computational cost, and risk of introducing additional error. While the process has long been a part of the GATK Best Practices pipeline, it has recently fallen out of favor \parencite{van_der_auwera_geraldine_2020_b}. In the fourth chapter, I investigate the effect of base quality score recalibration on variant caller sensitivity and specificity.

%TODO: make this not suck
All together, this work explores many avenues for detecting variants in non-model organisms. 
There are many ways to do so, and many more that aren't discussed here.
Each has strengths and weaknesses, but understanding what these are is critical to success.
While choosing the correct method can be a challenging and daunting task, with careful preparation and rigorous examination of the available methods, any researcher can achieve satisfactory results.

\printbibliography[segment=\therefsegment]{}
